{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPT_API_text(prompt: str, user_input: str):\n",
    "  # åˆå§‹åŒ– Azure OpenAI å®¢æˆ¶ç«¯\n",
    "    try:\n",
    "        client = AzureOpenAI(\n",
    "            api_key=os.getenv(\"4OAPIKey\"),\n",
    "            api_version=\"2024-08-01-preview\",\n",
    "            azure_endpoint=os.getenv(\"4OEndpoint\")\n",
    "        )\n",
    "        # logging.info(\"Azure OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"åˆå§‹åŒ– Azure OpenAI å®¢æˆ¶ç«¯å¤±æ•—: {e}\")\n",
    "        return\n",
    "    try:\n",
    "        # logging.info(\"é–‹å§‹ç™¼é€ GPT API è«‹æ±‚\")\n",
    "        completion = client.chat.completions.create(\n",
    "            temperature=0,\n",
    "            model=\"gpt-4o-0806\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": user_input},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        response_content = completion.choices[0].message.content\n",
    "        prompt_tokens = completion.usage.prompt_tokens  # æç¤º (prompt) token æ•¸\n",
    "        completion_tokens = completion.usage.completion_tokens  # å›æ‡‰ (completion) token æ•¸\n",
    "\n",
    "        # logging.info(f\"API å›æ‡‰æˆåŠŸï¼ŒInput tokenæ•¸é‡: {prompt_tokens}, Output tokenæ•¸é‡: {completion_tokens})\")\n",
    "        # è¨ˆç®—æˆæœ¬ï¼ˆæŒ‰ 1M tokens è¨ˆåƒ¹ï¼‰\n",
    "        prompt_cost = (prompt_tokens / 1_000_000) * 2.5  # 2.5 ç¾é‡‘ / 1M tokens\n",
    "        completion_cost = (completion_tokens / 1_000_000) * 10  # 10 ç¾é‡‘ / 1M tokens\n",
    "        total_cost = prompt_cost + completion_cost\n",
    "        # é¡¯ç¤º token æ¶ˆè€—è³‡è¨Š\n",
    "        print(f\"Input Token: {prompt_tokens}\")\n",
    "        print(f\"Output Token: {completion_tokens}\")\n",
    "        print(f\"ç¸½å…±èŠ±è²»:{total_cost}ç¾é‡‘\")\n",
    "        print(f\"ç¸½å…±èŠ±è²»:{total_cost*32.85}å°å¹£\")\n",
    "        # print(response_content)\n",
    "        return response_content\n",
    "    except Exception as e:\n",
    "        logging.error(f\"API è«‹æ±‚å¤±æ•—: {e}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" \n",
    "è«‹å¹«æˆ‘åˆ†æuserè¼¸å…¥çš„è©•è«–åœ¨ Google è©•è«–ä¸Šçš„å…§å®¹ï¼Œä¸¦é‡å°ä»¥ä¸‹é‡é»æä¾›æ‘˜è¦ï¼š\n",
    "1. **é¤é»å£å‘³**ï¼ˆç¸½é«”è©•åƒ¹ã€ç‰¹è‰²ã€å¸¸è¦‹è©•è«–ï¼‰(10å€‹å­—ä»¥å…§) \n",
    "2. **åƒ¹ä½**ï¼ˆæ˜¯å¦åˆç†ã€æ€§åƒ¹æ¯”ã€èˆ‡é¡ä¼¼é¤å»³æ¯”è¼ƒï¼‰\n",
    "3. **æ¨è–¦é—œéµå­—**ï¼ˆå¸¸è¦‹çš„å¥½è©•/è² è©•é—œéµè©ï¼‰(10å€‹å­—ä»¥å…§)  \n",
    "4. **æ¨è–¦çš„èœè‰²**ï¼ˆè©•è«–ä¸­æœ€å¸¸è¢«æåŠçš„æ¨è–¦èœå“ï¼‰(10å€‹å­—ä»¥å…§)   \n",
    "è«‹ä¾ç…§ä»¥ä¸‹ç¯„ä¾‹æ ¼å¼è¼¸å‡º\n",
    "   - é¤å»³åç¨±ï¼š  \n",
    "   - ç¸½é«”è©•åƒ¹ï¼ˆ1~5åˆ†ï¼‰ï¼š  \n",
    "   - é¤é»å£å‘³ï¼š \n",
    "   - åƒ¹ä½ï¼š  \n",
    "   - æ¨è–¦é—œéµå­—ï¼š \n",
    "   - æ¨è–¦çš„èœè‰²ï¼š\n",
    "\"\"\"\n",
    "\n",
    "user_input =\"\"\"\n",
    "11PASTAé£Ÿç¾©_å—äº¬åº—\n",
    "è¦ºå¾—å¥—é¤çš„éºµåŒ…éå¸¸å¥½åƒï¼\n",
    "çƒ¤çš„é…¥é…¥è„†è„†çš„ï¼Œä¸€äººä¸€å€‹æœ‰ç¨®æ„çŒ¶æœªç›¡çš„æ„Ÿè¦ºã€‚\n",
    "ç¾©å¤§åˆ©éºµæœ‰å¤šåŠ ä¸€ä»½è”¬èœ+30å…ƒ\n",
    "å¤šäº†å¾ˆå¤šè‡é¡ï¼Œåƒèµ·ä¾†æ»¿è¶³\n",
    "\n",
    "æŠ«è–©é»äº†ç‡»é®­ï¼Œè¦ºå¾—æœ‰é»å¤ªé¹¹ï¼Œä½†å¾ˆå–œæ­¡æŠ«è–©çš„ã€Œé‚Šé‚Šã€é…¥é¦™å¥½åƒï¼Œæœ‰èˆ’æœçš„éº¥å‘³ğŸ‘\n",
    "\n",
    "å¥—é¤çš„æ²™æ‹‰ç®—è±ç››\n",
    "ç¾å¼æ¯”å–®é»çš„ç¾å¼ç¨å°æ¯\n",
    "ç”œé»ææ‹‰ç±³è˜‡é‚„ok\n",
    "\n",
    "1300ä¾†ç”¨é¤ä¾ç„¶å®¢æ»¿ï¼Œå»ºè­°å…ˆè¨‚ä½\n",
    "æ•´é«”ä¾†èªªæ˜¯æœƒå†å›è¨ªçš„é¤å»³ã€‚ \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Token: 405\n",
      "Output Token: 106\n",
      "ç¸½å…±èŠ±è²»:0.0020724999999999997ç¾é‡‘\n",
      "ç¸½å…±èŠ±è²»:0.06808162499999999å°å¹£\n"
     ]
    }
   ],
   "source": [
    "res = GPT_API_text(prompt=prompt,user_input=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- é¤å»³åç¨±ï¼š11PASTAé£Ÿç¾©_å—äº¬åº—  \n",
      "- ç¸½é«”è©•åƒ¹ï¼ˆ1~5åˆ†ï¼‰ï¼š4åˆ†  \n",
      "- é¤é»å£å‘³ï¼šéºµåŒ…é…¥è„†ï¼ŒæŠ«è–©åé¹¹  \n",
      "- åƒ¹ä½ï¼šåˆç†ï¼Œæ€§åƒ¹æ¯”é«˜  \n",
      "- æ¨è–¦é—œéµå­—ï¼šé…¥è„†ã€æ»¿è¶³ã€å®¢æ»¿  \n",
      "- æ¨è–¦çš„èœè‰²ï¼šå¥—é¤éºµåŒ…ã€ç‡»é®­æŠ«è–©\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"google_Comment.md\",\"w\") as f:\n",
    "    f.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crawler-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
